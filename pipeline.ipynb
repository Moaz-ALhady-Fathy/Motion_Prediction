{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"1\"\n",
    "\n",
    "from Code.track import detect\n",
    "from Code.get_prepared_data_sdd import prepared_data_sdd\n",
    "from Code.visualize_sdd_annotation import visualizeSddAnnotation\n",
    "from Code.extract_scene_seg import extract_scene_seg\n",
    "from Code.preprocess import To_npz\n",
    "import numpy as np\n",
    "\n",
    "video_path = 'many_people.mp4'\n",
    "\n",
    "#get the annotations from yolo and deepsort + resized images to 1920 x 1080\n",
    "yolo_time_start = time.time()\n",
    "dataset_resize,changelst , annotation = detect(video_path)\n",
    "yolo_time_end = time.time()\n",
    "\n",
    "#get box centre x,y for each person (traj_data)\n",
    "#person_box_data : boxes coordinates for all persons\n",
    "#other_box_data : boxes of other objects in the same frame with each targeted person\n",
    "traj_data, person_box_data, other_box_data  = prepared_data_sdd(annotation,changelst)\n",
    "\n",
    "#get the segmentation\n",
    "seg_time_start = time.time()\n",
    "model_path= 'deeplabv3_xception_ade20k_train/frozen_inference_graph.pb'\n",
    "seg_output= extract_scene_seg(dataset_resize,model_path,every =2) #every: step by which it will skip frames \n",
    "seg_time_end = time.time()\n",
    "\n",
    "#making npz which contanins arrays for details of the segmentation with annotations and person ids\n",
    "data=To_npz(8,12,traj_data,seg_output)\n",
    "np.savez(\"prepro_fold1/data_test.npz\", **data)\n",
    "\n",
    "simaug_time_start = time.time()\n",
    "!python Code/test.py prepro_fold1/ packed_models/ best_simaug_model \\\n",
    "--wd 0.001 --runId 0 --obs_len 8 --pred_len 12 --emb_size 32 --enc_hidden_size 256 \\\n",
    "--dec_hidden_size 256 --activation_func tanh --keep_prob 1.0 --num_epochs 30 \\\n",
    "--batch_size 12 --init_lr 0.3 --use_gnn --learning_rate_decay 0.95 --num_epoch_per_decay 5.0 \\\n",
    "--grid_loss_weight 1.0 --grid_reg_loss_weight 0.5 --save_period 3000 \\\n",
    "--scene_h 36 --scene_w 64 --scene_conv_kernel 3 --scene_conv_dim 64 \\\n",
    "--scene_grid_strides 2,4 --use_grids 1,0 --val_grid_num 0 --gpuid 0 --load_best \\\n",
    "--save_output sdd_out.p\n",
    "simaug_time_end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"yolo time : {yolo_time_end-yolo_time_start}\")\n",
    "print(f\"seg time : {seg_time_end-seg_time_start}\")\n",
    "print(f\"simaug time : {simaug_time_end-simaug_time_start}\")\n",
    "print(f\"whole time : {simaug_time_end-yolo_time_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the frames to visualize on it \n",
    "resized_videos_frames_path= r\"resized_videos_frames\"\n",
    "for i,j in dataset_resize.items():\n",
    "    cv2.imwrite(os.path.join(resized_videos_frames_path, \"%s_F_%08d.jpg\" % (\"stream\", i)), j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the frames with detection for one person \n",
    "person_id = 1\n",
    "frames_with_detection = visualizeSddAnnotation(dataset_resize, changelst, traj_data, person_box_data, other_box_data,person_id)\n",
    "frames_with_detection_path= r\"frames_with_detection\"\n",
    "for i,j in frames_with_detection.items():\n",
    "    plt.imshow(j)\n",
    "    plt.savefig(os.path.join(frames_with_detection_path, \"%s.jpg\" % ( i)), dpi=100)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the heatmap frames\n",
    "!echo fsdd_out_0.p,0_0_255 > sdd_run.lst\n",
    "!python code/visualize_output.py sdd_run.lst \"resized_videos_frames\" \"heatmap/\" \\\n",
    "--vis_num 50   --use_heatmap --ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the segmented frames\n",
    "segmented_path= r\"segmented\"\n",
    "for i,j in seg_output.items():\n",
    "    plt.imshow(j)\n",
    "    plt.savefig(os.path.join(segmented_path, \"%s.jpg\" % ( i)), dpi=100)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from Code.track_stream import detect\n",
    "from Code.queue import get_queue\n",
    "from Code.get_prepared_data_sdd import prepared_data_sdd\n",
    "from Code.visualize_sdd_annotation import visualizeSddAnnotation\n",
    "from Code.extract_scene_seg import extract_scene_seg\n",
    "from Code.preprocess import To_npz\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "# cv2.namedWindow(\"webcam\", cv2.WINDOW_NORMAL)\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(1):\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"1\"\n",
    "    images_try = get_queue(5,12,camera)\n",
    "    dataset_resize,changelst , annotation = detect(images_try)\n",
    "    traj_data, person_box_data, other_box_data = prepared_data_sdd(annotation,changelst)\n",
    "    # framesData = visualizeSddAnnotation(dataset_resize, changelst, traj_data, person_box_data, other_box_data)\n",
    "    model_path= 'deeplabv3_xception_ade20k_train/frozen_inference_graph.pb'\n",
    "    seg_output= extract_scene_seg(dataset_resize,model_path,every =2)\n",
    "    data=To_npz(4,6,traj_data,seg_output)\n",
    "    np.savez(\"prepro_fold1/data_test.npz\", **data)\n",
    "    !python Code/test.py prepro_fold1/ packed_models/ best_simaug_model \\\n",
    "    --wd 0.001 --runId 0 --obs_len 4 --pred_len 6 --emb_size 32 --enc_hidden_size 256 \\\n",
    "    --dec_hidden_size 256 --activation_func tanh --keep_prob 1.0 --num_epochs 30 \\\n",
    "    --batch_size 12 --init_lr 0.3 --use_gnn --learning_rate_decay 0.95 --num_epoch_per_decay 5.0 \\\n",
    "    --grid_loss_weight 1.0 --grid_reg_loss_weight 0.5 --save_period 3000 \\\n",
    "    --scene_h 36 --scene_w 64 --scene_conv_kernel 3 --scene_conv_dim 64 \\\n",
    "    --scene_grid_strides 2,4 --use_grids 1,0 --val_grid_num 0 --gpuid 0 --load_best \\\n",
    "    --save_output \"sdd_out_{i}.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
