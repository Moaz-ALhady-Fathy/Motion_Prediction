{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights from deep_sort_pytorch/deep_sort/deep/checkpoint/ckpt.t7... Done!\n",
      "YOLOv5  2021-11-21 torch 1.7.1+cu101 CUDA:0 (NVIDIA GeForce RTX 2070 with Max-Q Design, 8192MiB)\n",
      "\n",
      "YOLOv5  2021-11-21 torch 1.7.1+cu101 CUDA:0 (NVIDIA GeForce RTX 2070 with Max-Q Design, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 367 layers, 46533693 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"1\"\n",
    "\n",
    "from Code.track import detect\n",
    "from Code.get_prepared_data_sdd import prepared_data_sdd\n",
    "from Code.visualize_sdd_annotation import visualizeSddAnnotation\n",
    "from Code.extract_scene_seg import extract_scene_seg\n",
    "from Code.preprocess import To_npz\n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "yolo_time_start = time.time()\n",
    "dataset_resize,changelst , annotation = detect('many_people.mp4')\n",
    "yolo_time_end = time.time()\n",
    "\n",
    "traj_data, person_box_data, other_box_data  = prepared_data_sdd(annotation,changelst)\n",
    "\n",
    "seg_time_start = time.time()\n",
    "model_path= 'deeplabv3_xception_ade20k_train/frozen_inference_graph.pb'\n",
    "seg_output= extract_scene_seg(dataset_resize,model_path,every =100)\n",
    "seg_time_end = time.time()\n",
    "\n",
    "data=To_npz(8,12,traj_data,seg_output)\n",
    "np.savez(\"prepro_fold1/data_test.npz\", **data)\n",
    "\n",
    "simaug_time_start = time.time()\n",
    "!python Code/test.py prepro_fold1/ packed_models/ best_simaug_model \\\n",
    "--wd 0.001 --runId 0 --obs_len 8 --pred_len 12 --emb_size 32 --enc_hidden_size 256 \\\n",
    "--dec_hidden_size 256 --activation_func tanh --keep_prob 1.0 --num_epochs 30 \\\n",
    "--batch_size 12 --init_lr 0.3 --use_gnn --learning_rate_decay 0.95 --num_epoch_per_decay 5.0 \\\n",
    "--grid_loss_weight 1.0 --grid_reg_loss_weight 0.5 --save_period 3000 \\\n",
    "--scene_h 36 --scene_w 64 --scene_conv_kernel 3 --scene_conv_dim 64 \\\n",
    "--scene_grid_strides 2,4 --use_grids 1,0 --val_grid_num 0 --gpuid 0 --load_best \\\n",
    "--save_output sdd_out.p\n",
    "simaug_time_end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo time : 43.69891881942749\n",
      "seg time : 152.9190957546234\n",
      "simaug time : 409.57017850875854\n",
      "whole time : 611.6333334445953\n"
     ]
    }
   ],
   "source": [
    "print(f\"yolo time : {yolo_time_end-yolo_time_start}\")\n",
    "print(f\"seg time : {seg_time_end-seg_time_start}\")\n",
    "print(f\"simaug time : {simaug_time_end-simaug_time_start}\")\n",
    "print(f\"whole time : {simaug_time_end-yolo_time_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo fsdd_out_0.p,0_0_255 > sdd_run.lst\n",
    "path= r\"C:\\Users\\melsh\\project\\GProject\\output pictures\\resized_videos_frames\"\n",
    "for i,j in dataset_resize.items():\n",
    "    cv2.imwrite(os.path.join(path, \"%s_F_%08d.jpg\" % (\"stream\", i)), j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"seg_output.p\", \"wb\") as f:\n",
    "      pickle.dump(seg_output, f)\n",
    "framesData = visualizeSddAnnotation(dataset_resize, changelst, traj_data, person_box_data, other_box_data,1)\n",
    "with open(\"framesData.p\", \"wb\") as f:\n",
    "      pickle.dump(framesData, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python code/visualize_output.py sdd_run.lst \"output pictures/resized_videos_frames\" \"output pictures/sdd_vis_heatmap/\" \\\n",
    "--vis_num 1   --use_heatmap --ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "seg_output = pd.read_pickle(r\"seg_output.p\")\n",
    "framesData = pd.read_pickle(r\"framesData.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framesData_path= r\"C:\\Users\\melsh\\project\\GProject\\output pictures\\framesData\"\n",
    "for i,j in framesData.items():\n",
    "    plt.imshow(j)\n",
    "    plt.savefig(os.path.join(framesData_path, \"%s.jpg\" % ( i)), dpi=100)\n",
    "    plt.clf()\n",
    "segmented_path= r\"C:\\Users\\melsh\\project\\GProject\\output pictures\\segmented\"\n",
    "for i,j in seg_output.items():\n",
    "    plt.imshow(j)\n",
    "    plt.savefig(os.path.join(segmented_path, \"%s.jpg\" % ( i)), dpi=100)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from Code.track_stream import detect\n",
    "from Code.queue import get_queue\n",
    "from Code.get_prepared_data_sdd import prepared_data_sdd\n",
    "from Code.visualize_sdd_annotation import visualizeSddAnnotation\n",
    "from Code.extract_scene_seg import extract_scene_seg\n",
    "from Code.preprocess import To_npz\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "# cv2.namedWindow(\"webcam\", cv2.WINDOW_NORMAL)\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(1):\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"1\"\n",
    "    images_try = get_queue(5,12,camera)\n",
    "    dataset_resize,changelst , annotation = detect(images_try)\n",
    "    traj_data, person_box_data, other_box_data = prepared_data_sdd(annotation,changelst)\n",
    "    # framesData = visualizeSddAnnotation(dataset_resize, changelst, traj_data, person_box_data, other_box_data)\n",
    "    model_path= 'deeplabv3_xception_ade20k_train/frozen_inference_graph.pb'\n",
    "    seg_output= extract_scene_seg(dataset_resize,model_path,every =2)\n",
    "    data=To_npz(4,6,traj_data,seg_output)\n",
    "    np.savez(\"prepro_fold1/data_test.npz\", **data)\n",
    "    !python Code/test.py prepro_fold1/ packed_models/ best_simaug_model \\\n",
    "    --wd 0.001 --runId 0 --obs_len 4 --pred_len 6 --emb_size 32 --enc_hidden_size 256 \\\n",
    "    --dec_hidden_size 256 --activation_func tanh --keep_prob 1.0 --num_epochs 30 \\\n",
    "    --batch_size 12 --init_lr 0.3 --use_gnn --learning_rate_decay 0.95 --num_epoch_per_decay 5.0 \\\n",
    "    --grid_loss_weight 1.0 --grid_reg_loss_weight 0.5 --save_period 3000 \\\n",
    "    --scene_h 36 --scene_w 64 --scene_conv_kernel 3 --scene_conv_dim 64 \\\n",
    "    --scene_grid_strides 2,4 --use_grids 1,0 --val_grid_num 0 --gpuid 0 --load_best \\\n",
    "    --save_output \"sdd_out_{i}.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
